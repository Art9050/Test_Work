{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOhkFKtV96TfDXkZc0M3haV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Art9050/Test_Work/blob/main/WhoIsBlogger_(WIB).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестовое задание на парсинг информации и ее анализ от WhoIsBlogger"
      ],
      "metadata": {
        "id": "4Q2vVUOuZbJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С сайта dzen news (https://dzen.ru/news) необходимо собрать краткий текст и названия всех статей за последний месяц (на момент выполнения) с ключевым словом \"игра\".  \n",
        "Затем для полученных статей необходимо рассчитать топ-50 наиболее частотных слов и представить их в виде word (tag) cloud.  \n",
        "Данное задание необходимо выполнить с помощью python.  \n",
        "Для представления в виде word cloud можно использовать уже существующие библиотеки. Пример word cloud можно посмотреть по ссылке - https://altoona.psu.edu/sites/altoona/files/success-word-cloud.jpg\n",
        "\n"
      ],
      "metadata": {
        "id": "FaZMyWJ1-u45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gv2XtU0snNM",
        "outputId": "58af29af-c849-49bb-9c39-4e98e3129406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from pprint import pprint\n",
        "import re\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "_Ikebmd0YH4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738d7a74-1b9a-464e-b119-c330719f7b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install chromium, its driver, and selenium # https://gist.github.com/korakot/5c8e21a5af63966d80a676af0ce15067\n",
        "!apt install chromium-chromedriver\n",
        "!pip install selenium\n",
        "# set options to be headless, ..\n",
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ],
      "metadata": {
        "id": "0XAPus6mONF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf1d423-d3de-4af7-a5c6-4ca7d521df3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 liblzo2-2 libudev1 snapd squashfs-tools systemd-hwe-hwdb\n",
            "  udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 liblzo2-2 snapd squashfs-tools\n",
            "  systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 9 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 26.4 MB of archives.\n",
            "After this operation, 116 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.2 [595 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.11 [78.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.11 [1,557 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.58+22.04.1 [23.8 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.3 [2,908 B]\n",
            "Fetched 26.4 MB in 2s (16.7 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 120880 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.2_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.2) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../liblzo2-2_2.10-2build3_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.11_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.11) over (249.11-0ubuntu3.10) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.11) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 121087 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.11_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.11) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.58+22.04.1_amd64.deb ...\n",
            "Unpacking snapd (2.58+22.04.1) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.2) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.11) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.58+22.04.1) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.aa-prompt-listener.service → /lib/systemd/system/snapd.aa-prompt-listener.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 121320 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.3_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.3) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.3) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.11) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.15.2-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.23.1-py3-none-any.whl (448 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.3/448.3 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.3)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.15.2 trio-0.23.1 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# open it, go to a website, and get results\n",
        "url = 'https://dzen.ru/news'\n",
        "\n",
        "wd = webdriver.Chrome(options=options)\n",
        "wd.get(url)\n",
        "\n",
        "# html страницы\n",
        "page = wd.page_source\n",
        "# Закрыть браузер\n",
        "wd.quit()"
      ],
      "metadata": {
        "id": "2BhOcjHDPHFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(page, 'lxml')"
      ],
      "metadata": {
        "id": "nI39PBmhNasb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = soup.find_all(\"div\", class_=\"mg-card__shown-card\")"
      ],
      "metadata": {
        "id": "RZmRlOZBQIkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = r'\\bлодка\\b'\n",
        "# '\\bигра\\b'\n",
        "\n",
        "# текст статей удовлетворяющих условию\n",
        "text = str()\n",
        "\n",
        "\n",
        "for i in data:\n",
        "    title = unicodedata.normalize('NFKD', i.find(\"h2\", class_=\"mg-card__title\").text)\n",
        "    short_text = unicodedata.normalize('NFKD', i.find(\"div\", class_=\"mg-card__annotation\").text)\n",
        "\n",
        "\n",
        "    # title = i.find(\"h2\", class_=\"mg-card__title\").text\n",
        "    # short_text = i.find(\"div\", class_=\"mg-card__annotation\").text\n",
        "\n",
        "    # text = text + '; ' + title + '; ' + short_text + '; ' #test\n",
        "\n",
        "    # накопление статей удовлетворяющих условию\n",
        "    while(bool(re.search(reg, short_text.lower())) or bool(re.search(reg, title.lower()))):\n",
        "        text = text + title + '; ' + short_text + '; '\n",
        "        break\n",
        "    # Применение этого блока возможно только после применения функции по отбрасыванию знаков препинания\n",
        "    # '\\bигра\\b' с пробелами или знакам препинания по краям или без всего\n",
        "\n",
        "# Приведение текста к нижнему регистру\n",
        "text = text.lower()"
      ],
      "metadata": {
        "id": "rGpDozqRVPoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "R_LpF1J742rO",
        "outputId": "15ccfc79-066d-4ee2-8b93-e7ed5e6ca977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the sun: британская подлодка могла утонуть из-за неисправности глубиномера; атомная подводная лодка типа vanguard вмс великобритании с экипажем из 140 человек и ракетами судного дня \"трайдент-2\" едва не утонула в атлантике из-за выхода из строя глубиномера.; '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# бэкап\n",
        "text2 = text"
      ],
      "metadata": {
        "id": "OcM0VG-ZS0-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Переделать\n",
        "Ошибка в логике.\n",
        "\n",
        "1. Идея развернуть лямбда функцию для явного преобразования  \n",
        "2. Сделать токенизацию идобавлять слова в отдельный список только если их нет в исключениях\n",
        "\n"
      ],
      "metadata": {
        "id": "A_R584ZI8Cst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# востановить из бэкап\n",
        "text = text2\n",
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzq4fUBbS6vF",
        "outputId": "c6b6d526-eb02-4323-92e5-edfb884a0027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "260"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Строка ASCII символов , которые считаются знаки препинания в локали языка + символы переноса строки, табуляции, кавычки\n",
        "spec_chars = string.punctuation + '\\n\\xa0«»\\t—…'\n",
        "\n",
        "# список сто-слов для русского языка:\n",
        "russian_stopwords = stopwords.words(\"russian\")\n",
        "\n",
        "# Список стоп-слов может быть расширен с помощью стандартного метода extend:\n",
        "russian_stopwords.extend(['это', 'нею', 'со'])\n",
        "\n",
        "def remove_chars_from_text(text, chars):\n",
        "    # разделим text на символы, оставим только символы, не входящие в spec_chars и снова объединим список символов в строку\n",
        "    return \"\".join([ch for ch in text if ch not in chars])\n",
        "\n",
        "# Разбиваем текст на слова(токены)\n",
        "# text_tokens = word_tokenize(text)\n",
        "\n",
        "# удаление спец.символов, удаление цифр, удаление стоп-слов\n",
        "\n",
        "text = remove_chars_from_text(text, spec_chars)\n",
        "text = remove_chars_from_text(text, string.digits)\n",
        "\n",
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5pNtChRnsk3",
        "outputId": "efb4fda9-5bc5-455f-9e29-1717f9a2aa1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "247"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsqpWZzY5HdP",
        "outputId": "aa9c9ff5-2558-4c96-d7c1-d5465c9effe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the sun британская подлодка могла утонуть изза неисправности глубиномера атомная подводная лодка типа vanguard вмс великобритании с экипажем из  человек и ракетами судного дня трайдент едва не утонула в атлантике изза выхода из строя глубиномера \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_tokens = word_tokenize(text)\n",
        "text_without_stopworlds = remove_chars_from_text(text_tokens, stopwords.words(\"russian\"))\n",
        "# работает корректно если текст токенезирован. В обычном состоянии выдирает куски текста подходящие под стоп слова\n",
        "text_without_stopworlds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "Zby23iIRYOe6",
        "outputId": "690debe0-5413-49ef-c951-4cebe38f3ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thesunбританскаяподлодкамоглаутонутьиззанеисправностиглубиномераатомнаяподводнаялодкатипаvanguardвмсвеликобританииэкипажемчеловекракетамисудногоднятрайдентедваутонулаатлантикеиззавыходастрояглубиномера'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# количество слов в предобработанном тексте\n",
        "len(text_tokens)"
      ],
      "metadata": {
        "id": "VE1tNOFamR4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# список токенов преобразоваем к классу Text\n",
        "text = nltk.Text(text_tokens)\n",
        "type(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHMOfkU6opQh",
        "outputId": "b506f2df-7380-4931-ca5f-b1ebe1c0a555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.text.Text"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Для подсчёта статистики распределения частот слов в тексте применяется класс FreqDist (frequency distributions):\n",
        "fdist = FreqDist(text)"
      ],
      "metadata": {
        "id": "0KiRxUBPwTVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fdist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRiAaEiI8Vl6",
        "outputId": "1c6159ff-cea4-4288-ed04-e7f4ff504dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'в': 85, 'на': 47, 'и': 40, 'с': 26, 'по': 23, 'о': 17, 'США': 14, 'ноября': 14, 'что': 13, 'из': 13, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Перебрать список токенов и поудалять плохие слова"
      ],
      "metadata": {
        "id": "BrRoWyyD_Im6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализация текста нужна"
      ],
      "metadata": {
        "id": "qKNZ8prS_RSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование списка токенов в строку. Разделиеть \" \"\n",
        "text_raw = \" \".join(text)"
      ],
      "metadata": {
        "id": "zcQ52eqX3V-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_raw"
      ],
      "metadata": {
        "id": "2BPg2x648o_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Строим облако\n",
        "wordcloud = WordCloud().generate(text_raw)\n",
        "type(wordcloud)"
      ],
      "metadata": {
        "id": "WPzksxqB3QRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(wordcloud)"
      ],
      "metadata": {
        "id": "pWtM5n9y-iip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "wordCloud = WordCloud(width = 1000, height = 1000, background_color='black', colormap='Set2').generate(text_raw)\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(wordCloud)"
      ],
      "metadata": {
        "id": "0KsU81Mh9HNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Статья на habr нужной тематики](https://habr.com/ru/articles/517410/)\n",
        "\n",
        "[Тут статья с выбором слов без использования библиотек и отсечки стопслов](https://habr.com/ru/articles/580560/)"
      ],
      "metadata": {
        "id": "VKffEH-ZI9Nl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- проверка на наличия слова \"игра\" без учета регистра\n",
        "```\n",
        "если short_text или title есть \"игра\"\n",
        "```\n",
        "\n",
        "\n",
        "- если слово есть\n",
        "    - перибираем каждое слово отддельно\n",
        "        - добавить в DF"
      ],
      "metadata": {
        "id": "tTTjBnMUj9fP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## rss для удобного парсинга сайтов  \n",
        "```https://dzen.ru/help/website/rss-modify.html```\n",
        "\n",
        "\n",
        "```https://habr.com/ru/articles/689520/```"
      ],
      "metadata": {
        "id": "bOwSSREew006"
      }
    }
  ]
}